{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\Documents\\pythons\\request\n"
     ]
    }
   ],
   "source": [
    "flowers = ['baby', 'tana', 'hydrangeas', 'lisianthus', 'ping_pong', 'rossi', 'calimero', 'chrysanthemum']\n",
    "for flower in flowers:\n",
    "    if not os.path.exists(flower):\n",
    "            os.makedirs(flower)\n",
    "path = os.path.abspath(os.getcwd())\n",
    "print(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "site: https://dalat.flowers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROSSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_rossi = {}\n",
    "\n",
    "urls_rossi = ['https://dalat.flowers/302/7904_cuc-rossi-cam-orange-cty-10.html',\n",
    "        'https://dalat.flowers/302/11666_cuc-rossi-vang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11654_cuc-rossi-trang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11654_cuc-rossi-trang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11654_cuc-rossi-trang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11653_cuc-rossi-tim-5-canh.html',\n",
    "        'https://dalat.flowers/302/11652_cuc-rossi-hong-5-canh.html']\n",
    "\n",
    "file_list = os.listdir(path + '\\\\rossi')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_rossi:\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_rossi[unidecode('ROSSI').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "        \n",
    "for image in files_rossi:\n",
    "    if 'hinh-hoa' in files_rossi[image]:\n",
    "        r = requests.get(files_rossi[image], stream=True)\n",
    "        with open(files_rossi[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_rossi[image], stream=True)\n",
    "        with open(files_rossi[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_rossi[image]:\n",
    "        os.rename(files_rossi[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_rossi[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BABY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_baby = {}\n",
    "\n",
    "urls_baby = ['https://dalat.flowers/297/8803_baby-ha-lan-trang-100g.html',\n",
    "        'https://dalat.flowers/297/8589_baby-ha-lan-hong-100g.html',\n",
    "        'https://dalat.flowers/297/11820_hoa-baby-da-lat-500g.html',\n",
    "        'https://dalat.flowers/297/8457_hoa-baby-ha-lan-trang-1000gr.html']\n",
    "file_list = os.listdir(path + '\\\\baby')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_baby:\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_baby[unidecode('baby').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_baby:\n",
    "    if 'hinh-hoa' in files_baby[image]:\n",
    "        r = requests.get(files_baby[image], stream=True)\n",
    "        with open(files_baby[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_baby[image], stream=True)\n",
    "        with open(files_baby[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_baby[image]:\n",
    "        os.rename(files_baby[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_baby[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALIMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\ACER\\\\Documents\\\\pythons\\\\request\\\\alimero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10896\\1538772012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;34m'https://dalat.flowers/302/11504_cuc-calimero-xanh-5-canh.html'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         'https://dalat.flowers/302/11647_cuc-calimero-tim-5-canh.html']\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfile_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\alimero'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\ACER\\\\Documents\\\\pythons\\\\request\\\\alimero'"
     ]
    }
   ],
   "source": [
    "files_calimero = {}\n",
    "\n",
    "urls_calimero = ['https://dalat.flowers/302/11651_cuc-calimero-trang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11650_cuc-calimero-vang-nhuy-nau-5-canh.html',\n",
    "        'https://dalat.flowers/302/11649_cuc-calimero-hong-5-canh.html',\n",
    "        'https://dalat.flowers/302/11648_cuc-calimero-vang-5-canh.html',\n",
    "        'https://dalat.flowers/302/11504_cuc-calimero-xanh-5-canh.html',\n",
    "        'https://dalat.flowers/302/11647_cuc-calimero-tim-5-canh.html']\n",
    "file_list = os.listdir(path + '\\\\alimero')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_calimero:\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_baby[unidecode('calimero').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_calimero:\n",
    "    if 'hinh-hoa' in files_calimero[image]:\n",
    "        r = requests.get(files_calimero[image], stream=True)\n",
    "        with open(files_calimero[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_calimero[image], stream=True)\n",
    "        with open(files_calimero[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_calimero[image]:\n",
    "        os.rename(files_calimero[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_calimero[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrangeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_hydrangeas = {}\n",
    "\n",
    "urls_hydrangeas = ['https://dalat.flowers/297/11819_cam-tu-cau-5-canh.html',\n",
    "                   'https://dalat.flowers/86/6041_bo-hoa-tu-cau.html',\n",
    "                   'https://dalat.flowers/204/5039_hydrangea-hoa-cam-tu-cau.html',\n",
    "                   'https://dalat.flowers/297/6536_cam-tu-cau-xanh-a.html']\n",
    "file_list = os.listdir(path + '\\\\hydrangeas')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_hydrangeas:\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_hydrangeas[unidecode('hydrangeas').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_hydrangeas:\n",
    "    if 'hinh-hoa' in files_hydrangeas[image]:\n",
    "        r = requests.get(files_hydrangeas[image], stream=True)\n",
    "        with open(files_hydrangeas[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_hydrangeas[image], stream=True)\n",
    "        with open(files_hydrangeas[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_hydrangeas[image]:\n",
    "        os.rename(files_hydrangeas[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_hydrangeas[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisianthus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_lisianthus = {}\n",
    "\n",
    "urls_lisianthus = ['https://dalat.flowers/295/6535_cat-tuong-xanh-500g.html',\n",
    "        'https://dalat.flowers/295/6529_cat-tuong-trang-500g.html',\n",
    "        'https://dalat.flowers/295/6527_cat-tuong-tim-vien-500g.html',\n",
    "        'https://dalat.flowers/295/6523_cat-tuong-hong-vien-500g.html']\n",
    "file_list = os.listdir(path + '\\\\lisianthus')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_lisianthus :\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_lisianthus[unidecode('lisianthus').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_lisianthus:\n",
    "    if 'hinh-hoa' in files_lisianthus[image]:\n",
    "        r = requests.get(files_lisianthus[image], stream=True)\n",
    "        with open(files_lisianthus[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_lisianthus[image], stream=True)\n",
    "        with open(files_lisianthus[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_lisianthus[image]:\n",
    "        os.rename(files_lisianthus[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_lisianthus[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PING PONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pingpong = {}\n",
    "\n",
    "urls_pingpong = ['https://dalat.flowers/302/6932_cuc-ping-pong-trang-cty-10.html',\n",
    "                 'https://dalat.flowers/302/6933_hoa-cuc-ping-pong-vang-cty-10.html',\n",
    "                 'https://dalat.flowers/301/6546_cuc-pingpong-tim-10.html',\n",
    "                 'https://dalat.flowers/302/6936_cuc-ping-pong-xanh-cty-10.html',\n",
    "                 'https://dalat.flowers/302/11840_cuc-ping-pong-vang-10-canh.html',\n",
    "                 'https://dalat.flowers/302/6934_cuc-ping-pong-hong-cty-10.html',\n",
    "                 'https://dalat.flowers/221/5893_ping-pong-golden.html']\n",
    "file_list = os.listdir(path + '\\\\ping_pong')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_pingpong :\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_pingpong[unidecode('ping_pong').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_pingpong:\n",
    "    if 'hinh-hoa' in files_pingpong[image]:\n",
    "        r = requests.get(files_pingpong[image], stream=True)\n",
    "        with open(files_pingpong[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_pingpong[image], stream=True)\n",
    "        with open(files_pingpong[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_pingpong[image]:\n",
    "        os.rename(files_pingpong[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_pingpong[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_tana = {}\n",
    "\n",
    "urls_tana = ['https://dalat.flowers/86/8425_tana-moc-mac.html',\n",
    "            'https://dalat.flowers/86/11868_tana-baby.html',\n",
    "            'https://dalat.flowers/88/6251_binh-hoa-cuc-tana.html',\n",
    "            'https://dalat.flowers/297/6693_cuc-tana-10.html',\n",
    "            'https://dalat.flowers/86/8422_lovely-tana.html']\n",
    "file_list = os.listdir(path + '\\\\tana')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "for url in urls_tana :\n",
    "    x = requests.get(url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    \n",
    "    for elements in soup.find_all(\"div\", {\"class\":\"thumb-image\"}):\n",
    "        files_tana[unidecode('tana').replace(\" \", \"_\").lower() + \"_c_\" + str(i)] = 'https://dalat.flowers' + elements.find(\"img\")['src']\n",
    "        i += 1\n",
    "for image in files_tana:\n",
    "    if 'hinh-hoa' in files_tana[image]:\n",
    "        r = requests.get(files_tana[image], stream=True)\n",
    "        with open(files_tana[image].split(\"hinh-hoa/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    else:\n",
    "        r = requests.get(files_tana[image], stream=True)\n",
    "        with open(files_tana[image].split(\"album/\")[1], 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    if not os.path.exists(image.split(\"_c_\")[0]):\n",
    "        os.makedirs(image.split(\"_c_\")[0])\n",
    "    if 'hinh-hoa' in files_tana[image]:\n",
    "        os.rename(files_tana[image].split(\"hinh-hoa/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")\n",
    "    else:\n",
    "        os.rename(files_tana[image].split(\"album/\")[1], image.split(\"_c_\")[0] + '/' + image + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "site: https://hoatuoi360.vn/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_list = os.listdir(path + '\\\\tana')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "hrefs = {}\n",
    "\n",
    "\n",
    "\n",
    "x = requests.get('https://hoatuoi360.vn/cuc-tana/')\n",
    "soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "pages = 1\n",
    "for element in soup.find_all(\"p\", {\"class\":\"page-nav\"}):\n",
    "    for a in element.find_all(\"a\",href=True):\n",
    "        if a.text.isdigit():\n",
    "            if pages is not None:\n",
    "                if pages < int(a.text):\n",
    "                    pages = int(a.text)\n",
    "            else:\n",
    "                pages = int(a.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "urls = []\n",
    "for y in range(1, pages+1):\n",
    "    x = requests.get('https://hoatuoi360.vn/cuc-tana?page='+str(y))\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"ul\", {\"id\":\"include_load_pages\"}):\n",
    "        for url in box.find_all(\"li\"):\n",
    "            urls.append(url.find(\"a\", href=True)['href'])\n",
    "for url in urls:\n",
    "    x = requests.get('https://hoatuoi360.vn/' + url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"div\", {\"class\":\"m-i2-cpd box-uof-img\"}):\n",
    "        for image in box.find_all(\"img\"):\n",
    "            r = requests.get('https://hoatuoi360.vn/' + image.attrs['src'].split(\"../\")[1], stream=True)\n",
    "            with open(image.attrs['src'].split(\"thumb/\")[1], 'wb') as f:\n",
    "                    r.raw.decode_content = True\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "            if not os.path.exists('tana'):\n",
    "                os.makedirs(image.split(\"_c_\")[0])\n",
    "            os.rename(image.attrs['src'].split(\"thumb/\")[1], 'tana/tana_c_' + str(i) + \".jpg\")\n",
    "            i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BABY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path + '\\\\baby')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "hrefs = {}\n",
    "\n",
    "\n",
    "\n",
    "x = requests.get('https://hoatuoi360.vn/hoa-baby/')\n",
    "soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "pages = 1\n",
    "for element in soup.find_all(\"p\", {\"class\":\"page-nav\"}):\n",
    "    for a in element.find_all(\"a\",href=True):\n",
    "        if a.text.isdigit():\n",
    "            if pages is not None:\n",
    "                if pages < int(a.text):\n",
    "                    pages = int(a.text)\n",
    "            else:\n",
    "                pages = int(a.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "urls = []\n",
    "for y in range(1, pages+1):\n",
    "    x = requests.get('https://hoatuoi360.vn/hoa-baby?page='+str(y))\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"ul\", {\"id\":\"include_load_pages\"}):\n",
    "        for url in box.find_all(\"li\"):\n",
    "            urls.append(url.find(\"a\", href=True)['href'])\n",
    "for url in urls:\n",
    "    x = requests.get('https://hoatuoi360.vn/' + url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"div\", {\"class\":\"m-i2-cpd box-uof-img\"}):\n",
    "        for image in box.find_all(\"img\"):\n",
    "            r = requests.get('https://hoatuoi360.vn/' + image.attrs['src'].split(\"../\")[1], stream=True)\n",
    "            with open(image.attrs['src'].split(\"thumb/\")[1], 'wb') as f:\n",
    "                    r.raw.decode_content = True\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "            if not os.path.exists('baby'):\n",
    "                os.makedirs(image.split(\"_c_\")[0])\n",
    "            os.rename(image.attrs['src'].split(\"thumb/\")[1], 'baby/baby_c_' + str(i) + \".jpg\")\n",
    "            i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrangeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path + '\\\\hydrangeas')\n",
    "i = 1\n",
    "for file in file_list:\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "hrefs = {}\n",
    "\n",
    "\n",
    "\n",
    "x = requests.get('https://hoatuoi360.vn/cam-tu-cau/')\n",
    "soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "pages = 1\n",
    "for element in soup.find_all(\"p\", {\"class\":\"page-nav\"}):\n",
    "    for a in element.find_all(\"a\",href=True):\n",
    "        if a.text.isdigit():\n",
    "            if pages is not None:\n",
    "                if pages < int(a.text):\n",
    "                    pages = int(a.text)\n",
    "            else:\n",
    "                pages = int(a.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "urls = []\n",
    "for y in range(1, pages+1):\n",
    "    x = requests.get('https://hoatuoi360.vn/cam-tu-cau?page='+str(y))\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"ul\", {\"id\":\"include_load_pages\"}):\n",
    "        for url in box.find_all(\"li\"):\n",
    "            urls.append(url.find(\"a\", href=True)['href'])\n",
    "for url in urls:\n",
    "    x = requests.get('https://hoatuoi360.vn/' + url)\n",
    "    soup = BeautifulSoup(x.text, \"html.parser\")\n",
    "    for box in soup.find_all(\"div\", {\"class\":\"m-i2-cpd box-uof-img\"}):\n",
    "        for image in box.find_all(\"img\"):\n",
    "            r = requests.get('https://hoatuoi360.vn/' + image.attrs['src'].split(\"../\")[1], stream=True)\n",
    "            with open(image.attrs['src'].split(\"thumb/\")[1], 'wb') as f:\n",
    "                    r.raw.decode_content = True\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "            if not os.path.exists('baby'):\n",
    "                os.makedirs(image.split(\"_c_\")[0])\n",
    "            os.rename(image.attrs['src'].split(\"thumb/\")[1], 'hydrangeas/hydrangeas_c_' + str(i) + \".jpg\")\n",
    "            i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
